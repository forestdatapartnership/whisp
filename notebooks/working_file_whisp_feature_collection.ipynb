{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "250b53cc",
   "metadata": {},
   "source": [
    "### Whisp a feature collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed47318",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38ac967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install geojson\n",
    "# !pip install pandera[io]\n",
    "import ee\n",
    "import geojson\n",
    "import pandas as pd\n",
    "from pandera import Column, io\n",
    "from pathlib import Path\n",
    "from whisp.src.pd_schemas import data_lookup_type\n",
    "from whisp.src.data_conversion import create_feature_collection\n",
    "\n",
    "import whisp\n",
    "\n",
    "ee.Authenticate()\n",
    "ee.Initialize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7532a17",
   "metadata": {},
   "source": [
    "Get a feature collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7d644b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnell\\Documents\\GitHub\\whisp_sustaain\\test\\fixtures\\geojson_example.geojson\n"
     ]
    }
   ],
   "source": [
    "# asset_id = \"projects/ee-whisp/assets/example_asset\" # asset id\n",
    "# asset_id = \"projects/fdap-remi/assets/CFI_cocoa_GHA\"\n",
    "# roi = ee.FeatureCollection(asset_id) # load feature collection asset\n",
    "\n",
    "# earthengine authenticate\n",
    "GEOJSON_EXAMPLE_FILEPATH = (\n",
    "    # Path(__file__).parents[1] / \"fixtures\" / \"geojson_example.geojson\"\n",
    "    Path.cwd().parents[0]/ \"test\" / \"fixtures\" / \"geojson_example.geojson\"\n",
    ")\n",
    "print(GEOJSON_EXAMPLE_FILEPATH)\n",
    "# print (roi.size().getInfo())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fce13c5",
   "metadata": {},
   "source": [
    "Whisp it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f5fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received geojson_filepath: c:\\Users\\Arnell\\Documents\\GitHub\\whisp_sustaain\\test\\fixtures\\geojson_example.geojson\n",
      "Reading GeoJSON file from: c:\\Users\\Arnell\\Documents\\GitHub\\whisp_sustaain\\test\\fixtures\\geojson_example.geojson\n",
      "['Plot_area_ha', 'KBA', 'Cocoa_bnetd', 'Oil_palm_Descals', 'ESA_fire_before_2020', 'ESA_fire_2001', 'ESA_fire_2002', 'ESA_fire_2003', 'ESA_fire_2004', 'ESA_fire_2005', 'ESA_fire_2006', 'ESA_fire_2007', 'ESA_fire_2008', 'ESA_fire_2009', 'ESA_fire_2010', 'ESA_fire_2011', 'ESA_fire_2012', 'ESA_fire_2013', 'ESA_fire_2014', 'ESA_fire_2015', 'ESA_fire_2016', 'ESA_fire_2017', 'ESA_fire_2018', 'ESA_fire_2019', 'ESA_fire_2020', 'ESA_TC_2020', 'Cocoa_ETH', 'Oil_palm_FDaP', 'GFC_TC_2020', 'GFC_loss_after_2020', 'GFC_loss_before_2020', 'GFC_loss_year_2001', 'GFC_loss_year_2002', 'GFC_loss_year_2003', 'GFC_loss_year_2004', 'GFC_loss_year_2005', 'GFC_loss_year_2006', 'GFC_loss_year_2007', 'GFC_loss_year_2008', 'GFC_loss_year_2009', 'GFC_loss_year_2010', 'GFC_loss_year_2011', 'GFC_loss_year_2012', 'GFC_loss_year_2013', 'GFC_loss_year_2014', 'GFC_loss_year_2015', 'GFC_loss_year_2016', 'GFC_loss_year_2017', 'GFC_loss_year_2018', 'GFC_loss_year_2019', 'GFC_loss_year_2020', 'GFC_loss_year_2021', 'GFC_loss_year_2022', 'GFC_loss_year_2023', 'GLAD_Primary', 'JAXA_FNF_2020', 'EUFO_2020', 'TMF_plant', 'TMF_undist', 'MODIS_fire_after_2020', 'MODIS_fire_before_2020', 'MODIS_fire_2000', 'MODIS_fire_2001', 'MODIS_fire_2002', 'MODIS_fire_2003', 'MODIS_fire_2004', 'MODIS_fire_2005', 'MODIS_fire_2006', 'MODIS_fire_2007', 'MODIS_fire_2008', 'MODIS_fire_2009', 'MODIS_fire_2010', 'MODIS_fire_2011', 'MODIS_fire_2012', 'MODIS_fire_2013', 'MODIS_fire_2014', 'MODIS_fire_2015', 'MODIS_fire_2016', 'MODIS_fire_2017', 'MODIS_fire_2018', 'MODIS_fire_2019', 'MODIS_fire_2020', 'MODIS_fire_2021', 'MODIS_fire_2022', 'MODIS_fire_2023', 'MODIS_fire_2024', 'RADD_after_2020', 'RADD_before_2020', 'RADD_year_2019', 'RADD_year_2020', 'RADD_year_2021', 'RADD_year_2022', 'RADD_year_2023', 'RADD_year_2024', 'Rubber_RBGE', 'TMF_def_after_2020', 'TMF_def_before_2020', 'TMF_def_2000', 'TMF_def_2001', 'TMF_def_2002', 'TMF_def_2003', 'TMF_def_2004', 'TMF_def_2005', 'TMF_def_2006', 'TMF_def_2007', 'TMF_def_2008', 'TMF_def_2009', 'TMF_def_2010', 'TMF_def_2011', 'TMF_def_2012', 'TMF_def_2013', 'TMF_def_2014', 'TMF_def_2015', 'TMF_def_2016', 'TMF_def_2017', 'TMF_def_2018', 'TMF_def_2019', 'TMF_def_2020', 'TMF_def_2021', 'TMF_def_2022', 'TMF_deg_after_2020', 'TMF_deg_before_2020', 'TMF_deg_2000', 'TMF_deg_2001', 'TMF_deg_2002', 'TMF_deg_2003', 'TMF_deg_2004', 'TMF_deg_2005', 'TMF_deg_2006', 'TMF_deg_2007', 'TMF_deg_2008', 'TMF_deg_2009', 'TMF_deg_2010', 'TMF_deg_2011', 'TMF_deg_2012', 'TMF_deg_2013', 'TMF_deg_2014', 'TMF_deg_2015', 'TMF_deg_2016', 'TMF_deg_2017', 'TMF_deg_2018', 'TMF_deg_2019', 'TMF_deg_2020', 'TMF_deg_2021', 'TMF_deg_2022', 'WDPA']\n",
      "{'type': 'Feature', 'geometry': None, 'id': '0', 'properties': {'Admin_Level_1': 'Ashanti Region', 'Centroid_lat': 6.159539574278987, 'Centroid_lon': -1.6119419952259373, 'Cocoa_ETH': 0, 'Cocoa_bnetd': 0, 'Country': 'GHA', 'ESA_TC_2020': 1.939, 'ESA_fire_2001': 0, 'ESA_fire_2002': 0, 'ESA_fire_2003': 0, 'ESA_fire_2004': 0, 'ESA_fire_2005': 0, 'ESA_fire_2006': 0, 'ESA_fire_2007': 0, 'ESA_fire_2008': 0, 'ESA_fire_2009': 0, 'ESA_fire_2010': 0, 'ESA_fire_2011': 0, 'ESA_fire_2012': 0, 'ESA_fire_2013': 0, 'ESA_fire_2014': 0, 'ESA_fire_2015': 0, 'ESA_fire_2016': 0, 'ESA_fire_2017': 0, 'ESA_fire_2018': 0, 'ESA_fire_2019': 0, 'ESA_fire_2020': 0, 'ESA_fire_before_2020': 0, 'EUFO_2020': 0.363, 'GFC_TC_2020': 0.387, 'GFC_loss_after_2020': 0, 'GFC_loss_before_2020': 1.552, 'GFC_loss_year_2001': 0, 'GFC_loss_year_2002': 0.062, 'GFC_loss_year_2003': 0, 'GFC_loss_year_2004': 0, 'GFC_loss_year_2005': 0, 'GFC_loss_year_2006': 0, 'GFC_loss_year_2007': 0, 'GFC_loss_year_2008': 0, 'GFC_loss_year_2009': 0, 'GFC_loss_year_2010': 0, 'GFC_loss_year_2011': 0, 'GFC_loss_year_2012': 0, 'GFC_loss_year_2013': 0, 'GFC_loss_year_2014': 0.363, 'GFC_loss_year_2015': 0, 'GFC_loss_year_2016': 0.951, 'GFC_loss_year_2017': 0.177, 'GFC_loss_year_2018': 0, 'GFC_loss_year_2019': 0, 'GFC_loss_year_2020': 0, 'GFC_loss_year_2021': 0, 'GFC_loss_year_2022': 0, 'GFC_loss_year_2023': 0, 'GLAD_Primary': 0, 'Geometry_type': 'Polygon', 'JAXA_FNF_2020': 1.939, 'KBA': 0, 'MODIS_fire_2000': 0, 'MODIS_fire_2001': 0, 'MODIS_fire_2002': 0, 'MODIS_fire_2003': 0, 'MODIS_fire_2004': 0, 'MODIS_fire_2005': 0, 'MODIS_fire_2006': 0, 'MODIS_fire_2007': 0, 'MODIS_fire_2008': 0, 'MODIS_fire_2009': 0, 'MODIS_fire_2010': 0, 'MODIS_fire_2011': 0, 'MODIS_fire_2012': 0, 'MODIS_fire_2013': 0, 'MODIS_fire_2014': 0, 'MODIS_fire_2015': 0, 'MODIS_fire_2016': 0, 'MODIS_fire_2017': 0, 'MODIS_fire_2018': 0, 'MODIS_fire_2019': 0, 'MODIS_fire_2020': 0, 'MODIS_fire_2021': 0, 'MODIS_fire_2022': 0, 'MODIS_fire_2023': 0, 'MODIS_fire_2024': 0, 'MODIS_fire_after_2020': 0, 'MODIS_fire_before_2020': 0, 'Oil_palm_Descals': 0, 'Oil_palm_FDaP': 0.048, 'Plot_area_ha': '1.939', 'RADD_after_2020': 0, 'RADD_before_2020': 0, 'RADD_year_2019': 0, 'RADD_year_2020': 0, 'RADD_year_2021': 0, 'RADD_year_2022': 0, 'RADD_year_2023': 0, 'RADD_year_2024': 0, 'Rubber_RBGE': 0, 'TMF_def_2000': 0, 'TMF_def_2001': 0.101, 'TMF_def_2002': 0, 'TMF_def_2003': 0, 'TMF_def_2004': 0, 'TMF_def_2005': 0, 'TMF_def_2006': 0, 'TMF_def_2007': 0, 'TMF_def_2008': 0, 'TMF_def_2009': 0, 'TMF_def_2010': 0, 'TMF_def_2011': 0, 'TMF_def_2012': 0.004, 'TMF_def_2013': 0.04, 'TMF_def_2014': 0.212, 'TMF_def_2015': 0.065, 'TMF_def_2016': 0, 'TMF_def_2017': 0.089, 'TMF_def_2018': 0, 'TMF_def_2019': 0, 'TMF_def_2020': 0, 'TMF_def_2021': 0, 'TMF_def_2022': 0, 'TMF_def_after_2020': 0, 'TMF_def_before_2020': 0.511, 'TMF_deg_2000': 0, 'TMF_deg_2001': 0.615, 'TMF_deg_2002': 0, 'TMF_deg_2003': 0, 'TMF_deg_2004': 0, 'TMF_deg_2005': 0, 'TMF_deg_2006': 0, 'TMF_deg_2007': 0.022, 'TMF_deg_2008': 0, 'TMF_deg_2009': 0, 'TMF_deg_2010': 0, 'TMF_deg_2011': 0, 'TMF_deg_2012': 0, 'TMF_deg_2013': 0, 'TMF_deg_2014': 0, 'TMF_deg_2015': 0, 'TMF_deg_2016': 0, 'TMF_deg_2017': 0, 'TMF_deg_2018': 0, 'TMF_deg_2019': 0, 'TMF_deg_2020': 0, 'TMF_deg_2021': 0, 'TMF_deg_2022': 0, 'TMF_deg_after_2020': 0, 'TMF_deg_before_2020': 0.637, 'TMF_plant': 0, 'TMF_undist': 0, 'Unit': 'ha', 'WDPA': 0, 'water_flag': '-'}}\n",
      "Using cached schema.\n",
      "[reformat.py | log_missing_columns() | l.335] WARNING: The following columns in 'df_stats' did not match any columns in the schema: KBA, MODIS_fire_2000\n",
      "[reformat.py | log_missing_columns() | l.343] WARNING: The following columns in the schema did not match any columns in 'df_stats': Plot_id, Geo_id\n",
      "DataFrame validated successfully\n"
     ]
    }
   ],
   "source": [
    "# df_stats = whisp.whisp_stats_geojson_to_df(GEOJSON_EXAMPLE_FILEPATH)\n",
    "\n",
    "df_formatted_stats = whisp.whisp_formatted_stats_geojson_to_df(GEOJSON_EXAMPLE_FILEPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bce20b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_stats\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_stats' is not defined"
     ]
    }
   ],
   "source": [
    "# geojson_path = r\"c:\\Users\\Arnell\\Documents\\GitHub\\whisp_sustaain\\input_examples\\geojson_example.geojson\"\n",
    "# roi = geojson_path_to_ee(geojson_path) # convert geojson to feature collection`\n",
    "\n",
    "\n",
    "# df_stats = whisp.whisp_stats_geojson_to_df(geojson_path)\n",
    "\n",
    "# df_stats = whisp.whisp_stats_ee_to_df(roi)\n",
    "\n",
    "# df_stats = whisp.whisp_stats_ee_to_drive(roi)\n",
    "\n",
    "# try:\n",
    "#     cached_schema = whisp.load_schema_if_any_file_changed(None) # using default lookups\n",
    "\n",
    "#     validated_df = whisp.validate_dataframe(cached_schema, df_stats)\n",
    "#     # print(\"DataFrame validated successfully.\")\n",
    "# except Exception as e:\n",
    "#     print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ad5bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot_id</th>\n",
       "      <th>Geo_id</th>\n",
       "      <th>Plot_area_ha</th>\n",
       "      <th>Geometry_type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Admin_Level_1</th>\n",
       "      <th>Centroid_lon</th>\n",
       "      <th>Centroid_lat</th>\n",
       "      <th>Unit</th>\n",
       "      <th>water_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>TMF_def_before_2020</th>\n",
       "      <th>GFC_loss_before_2020</th>\n",
       "      <th>ESA_fire_before_2020</th>\n",
       "      <th>MODIS_fire_before_2020</th>\n",
       "      <th>RADD_before_2020</th>\n",
       "      <th>TMF_deg_after_2020</th>\n",
       "      <th>TMF_def_after_2020</th>\n",
       "      <th>GFC_loss_after_2020</th>\n",
       "      <th>MODIS_fire_after_2020</th>\n",
       "      <th>RADD_after_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.939000</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>GHA</td>\n",
       "      <td>Ashanti Region</td>\n",
       "      <td>-1.611942</td>\n",
       "      <td>6.159540</td>\n",
       "      <td>ha</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511</td>\n",
       "      <td>1.552000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>GHA</td>\n",
       "      <td>Western Region</td>\n",
       "      <td>-2.157144</td>\n",
       "      <td>5.981149</td>\n",
       "      <td>ha</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.212999</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>IDN</td>\n",
       "      <td>South Sumatra</td>\n",
       "      <td>103.956096</td>\n",
       "      <td>-3.054668</td>\n",
       "      <td>ha</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>22.218</td>\n",
       "      <td>31.021999</td>\n",
       "      <td>31.212999</td>\n",
       "      <td>6.403</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.882000</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>IDN</td>\n",
       "      <td>South Sumatra</td>\n",
       "      <td>103.977512</td>\n",
       "      <td>-3.083808</td>\n",
       "      <td>ha</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>4.546</td>\n",
       "      <td>9.043000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.279000</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>CIV</td>\n",
       "      <td>Lagunes</td>\n",
       "      <td>-4.101646</td>\n",
       "      <td>5.711935</td>\n",
       "      <td>ha</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>2.535</td>\n",
       "      <td>3.194000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.615000</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>CIV</td>\n",
       "      <td>Montagnes</td>\n",
       "      <td>-7.507022</td>\n",
       "      <td>6.071468</td>\n",
       "      <td>ha</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959</td>\n",
       "      <td>1.956000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Plot_id  Geo_id  Plot_area_ha Geometry_type Country   Admin_Level_1  \\\n",
       "0      NaN     NaN      1.939000       Polygon     GHA  Ashanti Region   \n",
       "1      NaN     NaN     16.600000       Polygon     GHA  Western Region   \n",
       "2      NaN     NaN     31.212999       Polygon     IDN   South Sumatra   \n",
       "3      NaN     NaN     20.882000       Polygon     IDN   South Sumatra   \n",
       "4      NaN     NaN      8.279000       Polygon     CIV         Lagunes   \n",
       "5      NaN     NaN      3.615000       Polygon     CIV       Montagnes   \n",
       "\n",
       "   Centroid_lon  Centroid_lat Unit water_flag  ...  TMF_def_before_2020  \\\n",
       "0     -1.611942      6.159540   ha          -  ...                0.511   \n",
       "1     -2.157144      5.981149   ha          -  ...                0.000   \n",
       "2    103.956096     -3.054668   ha          -  ...               22.218   \n",
       "3    103.977512     -3.083808   ha          -  ...                4.546   \n",
       "4     -4.101646      5.711935   ha          -  ...                2.535   \n",
       "5     -7.507022      6.071468   ha          -  ...                0.959   \n",
       "\n",
       "   GFC_loss_before_2020  ESA_fire_before_2020  MODIS_fire_before_2020  \\\n",
       "0              1.552000              0.000000                   0.000   \n",
       "1              0.000000              0.000000                   0.000   \n",
       "2             31.021999             31.212999                   6.403   \n",
       "3              9.043000              0.000000                   0.000   \n",
       "4              3.194000              0.000000                   0.000   \n",
       "5              1.956000              0.000000                   0.000   \n",
       "\n",
       "   RADD_before_2020  TMF_deg_after_2020  TMF_def_after_2020  \\\n",
       "0              0.00               0.000                 0.0   \n",
       "1              1.11               0.089                 0.0   \n",
       "2              0.00               0.000                 0.0   \n",
       "3              0.00               0.714                 0.0   \n",
       "4              0.00               0.000                 0.0   \n",
       "5              0.00               0.000                 0.0   \n",
       "\n",
       "   GFC_loss_after_2020  MODIS_fire_after_2020  RADD_after_2020  \n",
       "0                0.000                    0.0            0.000  \n",
       "1                0.000                    0.0            1.063  \n",
       "2                0.000                    0.0            0.000  \n",
       "3                0.000                    0.0            0.000  \n",
       "4                1.602                    0.0            0.001  \n",
       "5                0.000                    0.0            0.000  \n",
       "\n",
       "[6 rows x 153 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d70ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_directory = 'C:/Users/Arnell/OneDrive - Food and Agriculture Organization/project_work/p0004_commodity_mapper_support/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5df37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.to_csv(out_directory+'whisp_output_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2ecbf7-d86f-425c-9c93-80ce21f3dff2",
   "metadata": {},
   "source": [
    "Calculate EUDR risk category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4cd1b5c-41ac-4d3c-af26-a47db3d48af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with name of your CSV file \n",
    "# NB if skipped 'Add Geo ids' should set to \"out_directory/whisp_output_table.csv\" \n",
    "\n",
    "csv_file_input =out_directory+'whisp_output_table.csv'\n",
    "\n",
    "# import csv as a dataframe\n",
    "df_w_stats = pd.read_csv(csv_file_input)\n",
    "\n",
    "df_w_risk = whisp.whisp_risk(\n",
    "    df = df_w_stats, \n",
    "    ind_1_pcent_threshold=10,\n",
    "    ind_2_pcent_threshold=10,\n",
    "    ind_3_pcent_threshold=0,\n",
    "    ind_4_pcent_threshold=0,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a15577b-44bb-4792-98ef-95fd6bc1aabb",
   "metadata": {},
   "source": [
    "Display table with risk columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c62b10e-7484-47cd-9f73-40f612be5407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Plot_id</th>\n",
       "      <th>Geo_id</th>\n",
       "      <th>Plot_area_ha</th>\n",
       "      <th>Geometry_type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Admin_Level_1</th>\n",
       "      <th>Centroid_lon</th>\n",
       "      <th>Centroid_lat</th>\n",
       "      <th>Unit</th>\n",
       "      <th>...</th>\n",
       "      <th>TMF_deg_after_2020</th>\n",
       "      <th>TMF_def_after_2020</th>\n",
       "      <th>GFC_loss_after_2020</th>\n",
       "      <th>MODIS_fire_after_2020</th>\n",
       "      <th>RADD_after_2020</th>\n",
       "      <th>Indicator_1_treecover</th>\n",
       "      <th>Indicator_2_commodities</th>\n",
       "      <th>Indicator_3_disturbance_before_2020</th>\n",
       "      <th>Indicator_4_disturbance_after_2020</th>\n",
       "      <th>EUDR_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.939</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>GHA</td>\n",
       "      <td>Ashanti Region</td>\n",
       "      <td>-1.611942</td>\n",
       "      <td>6.159540</td>\n",
       "      <td>ha</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.600</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>GHA</td>\n",
       "      <td>Western Region</td>\n",
       "      <td>-2.157144</td>\n",
       "      <td>5.981149</td>\n",
       "      <td>ha</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.063</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.213</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>IDN</td>\n",
       "      <td>South Sumatra</td>\n",
       "      <td>103.956096</td>\n",
       "      <td>-3.054668</td>\n",
       "      <td>ha</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.882</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>IDN</td>\n",
       "      <td>South Sumatra</td>\n",
       "      <td>103.977512</td>\n",
       "      <td>-3.083808</td>\n",
       "      <td>ha</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.279</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>CIV</td>\n",
       "      <td>Lagunes</td>\n",
       "      <td>-4.101646</td>\n",
       "      <td>5.711935</td>\n",
       "      <td>ha</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.615</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>CIV</td>\n",
       "      <td>Montagnes</td>\n",
       "      <td>-7.507022</td>\n",
       "      <td>6.071468</td>\n",
       "      <td>ha</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Plot_id  Geo_id  Plot_area_ha Geometry_type Country  \\\n",
       "0           0      NaN     NaN         1.939       Polygon     GHA   \n",
       "1           1      NaN     NaN        16.600       Polygon     GHA   \n",
       "2           2      NaN     NaN        31.213       Polygon     IDN   \n",
       "3           3      NaN     NaN        20.882       Polygon     IDN   \n",
       "4           4      NaN     NaN         8.279       Polygon     CIV   \n",
       "5           5      NaN     NaN         3.615       Polygon     CIV   \n",
       "\n",
       "    Admin_Level_1  Centroid_lon  Centroid_lat Unit  ... TMF_deg_after_2020  \\\n",
       "0  Ashanti Region     -1.611942      6.159540   ha  ...              0.000   \n",
       "1  Western Region     -2.157144      5.981149   ha  ...              0.089   \n",
       "2   South Sumatra    103.956096     -3.054668   ha  ...              0.000   \n",
       "3   South Sumatra    103.977512     -3.083808   ha  ...              0.714   \n",
       "4         Lagunes     -4.101646      5.711935   ha  ...              0.000   \n",
       "5       Montagnes     -7.507022      6.071468   ha  ...              0.000   \n",
       "\n",
       "   TMF_def_after_2020  GFC_loss_after_2020  MODIS_fire_after_2020  \\\n",
       "0                 0.0                0.000                    0.0   \n",
       "1                 0.0                0.000                    0.0   \n",
       "2                 0.0                0.000                    0.0   \n",
       "3                 0.0                0.000                    0.0   \n",
       "4                 0.0                1.602                    0.0   \n",
       "5                 0.0                0.000                    0.0   \n",
       "\n",
       "   RADD_after_2020  Indicator_1_treecover  Indicator_2_commodities  \\\n",
       "0            0.000                    yes                       no   \n",
       "1            1.063                    yes                       no   \n",
       "2            0.000                    yes                      yes   \n",
       "3            0.000                    yes                       no   \n",
       "4            0.001                    yes                      yes   \n",
       "5            0.000                    yes                      yes   \n",
       "\n",
       "   Indicator_3_disturbance_before_2020  Indicator_4_disturbance_after_2020  \\\n",
       "0                                  yes                                  no   \n",
       "1                                  yes                                 yes   \n",
       "2                                  yes                                  no   \n",
       "3                                  yes                                 yes   \n",
       "4                                  yes                                 yes   \n",
       "5                                  yes                                  no   \n",
       "\n",
       "   EUDR_risk  \n",
       "0        low  \n",
       "1        low  \n",
       "2        low  \n",
       "3        low  \n",
       "4        low  \n",
       "5        low  \n",
       "\n",
       "[6 rows x 159 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c0019-585e-4598-8c54-c628625f5f80",
   "metadata": {},
   "source": [
    "Export table with risk columns to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afa539dd-bb4c-44f7-922f-79e2644631a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file=out_directory+'whisp_output_table_w_risk.csv' # edit as required\n",
    "\n",
    "df_w_risk.to_csv(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27cfd857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Auto-iterate through all files in the root folder.\n",
    "# file_list = drive.ListFile({'q': \"'root' in parents and trashed=false\"}).GetList()\n",
    "# for file1 in file_list:\n",
    "#   print('title: %s, id: %s' % (file1['title'], file1['id']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0673099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file1.GetContentFile(f\"{file1['whisp_output_table.csv']}\", mimetype='text/csv')\n",
    "\n",
    "# file_id = '1hO851ZzYMVu882XWY4xoFEirE8Fa32-V'\n",
    "# docsfile = drive.CreateFile({'id':file_id })\n",
    "\n",
    "\n",
    "# file_title = 'whisp_results_output.csv'\n",
    "# docsfile = drive.CreateFile({'title':file_title })\n",
    "\n",
    "\n",
    "\n",
    "# docsfile.GetContentFile('example.csv', mimetype='text/csv')\n",
    "\n",
    "# df = pd.read_csv('example.csv', delimiter=',')\n",
    "\n",
    "# df\n",
    "\n",
    "## Replace 'YOUR_FOLDER_ID' with the actual folder ID of \"Whisp_results\"\n",
    "# folder_id = 'Whisp_results'\n",
    "\n",
    "# # Replace 'YOUR_FILE_TITLE' with the exact name of the file you're looking for\n",
    "# file_title = 'whisp_output_table.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20375297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import io\n",
    "# import json\n",
    "# import numpy as np\n",
    "# from google.auth.transport.requests import Request\n",
    "# from google.oauth2.credentials import Credentials\n",
    "# from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "# from googleapiclient.discovery import build\n",
    "# from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "# class GDrive:\n",
    "#     SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "\n",
    "#     def __init__(self):\n",
    "#         self.service = self.authenticate()\n",
    "\n",
    "#     def authenticate(self):\n",
    "#         creds = None\n",
    "#         if os.path.exists('token.json'):\n",
    "#             creds = Credentials.from_authorized_user_file('token.json', self.SCOPES)\n",
    "#         if not creds or not creds.valid:\n",
    "#             if creds and creds.expired and creds.refresh_token:\n",
    "#                 creds.refresh(Request())\n",
    "#             else:\n",
    "#                 flow = InstalledAppFlow.from_client_secrets_file(\n",
    "#                     'credentials.json', self.SCOPES)\n",
    "#                 creds = flow.run_local_server(port=0)\n",
    "#             with open('token.json', 'w') as token:\n",
    "#                 token.write(creds.to_json())\n",
    "\n",
    "#         return build('drive', 'v3', credentials=creds)\n",
    "\n",
    "#     def print_file_list(self):\n",
    "#         results = (\n",
    "#             self.service.files()\n",
    "#             .list(pageSize=30, fields=\"nextPageToken, files(id, name)\")\n",
    "#             .execute()\n",
    "#         )\n",
    "#         items = results.get(\"files\", [])\n",
    "#         if not items:\n",
    "#             print(\"No files found.\")\n",
    "#         else:\n",
    "#             print(\"Files:\")\n",
    "#             for item in items:\n",
    "#                 print(\"{0} ({1})\".format(item[\"name\"], item[\"id\"]))\n",
    "\n",
    "#     def get_items(self):\n",
    "#         results = (\n",
    "#             self.service.files()\n",
    "#             .list(\n",
    "#                 q=\"mimeType='image/tiff'\",\n",
    "#                 pageSize=1000,\n",
    "#                 fields=\"nextPageToken, files(id, name)\",\n",
    "#             )\n",
    "#             .execute()\n",
    "#         )\n",
    "#         items = results.get(\"files\", [])\n",
    "#         return items\n",
    "\n",
    "#     def get_id(self, items_to_search, filename):\n",
    "#         items = items_to_search\n",
    "#         namelist = np.array([items[i][\"name\"] for i in range(len(items))])\n",
    "#         idlist = np.array([items[i][\"id\"] for i in range(len(items))])\n",
    "#         file_pos = np.where(namelist == filename)\n",
    "\n",
    "#         if len(file_pos[0]) == 0:\n",
    "#             return (0, filename + \" not found\")\n",
    "#         else:\n",
    "#             return (1, idlist[file_pos])\n",
    "\n",
    "#     def download_file(self, filename, localpath, items_to_search):\n",
    "#         success, fId = self.get_id(items_to_search, filename)\n",
    "#         if success == 0:\n",
    "#             print(filename + \" not found\")\n",
    "#             return\n",
    "\n",
    "#         request = self.service.files().get_media(fileId=fId[0])\n",
    "#         fh = io.BytesIO()\n",
    "#         downloader = MediaIoBaseDownload(fh, request)\n",
    "#         done = False\n",
    "#         while not done:\n",
    "#             status, done = downloader.next_chunk()\n",
    "\n",
    "#         with open(localpath, \"wb\") as fo:\n",
    "#             fo.write(fh.getvalue())\n",
    "\n",
    "#     def delete_file(self, items_to_search, filename):\n",
    "#         success, fId = self.get_id(items_to_search, filename)\n",
    "\n",
    "#         if success == 0:\n",
    "#             print(filename + \" not found\")\n",
    "#             return\n",
    "\n",
    "#         self.service.files().delete(fileId=fId[0]).execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ce32765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# from google.oauth2.credentials import Credentials\n",
    "# from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "# from googleapiclient.discovery import build\n",
    "\n",
    "# # Define the scopes\n",
    "# SCOPES = ['https://www.googleapis.com/auth/drive.metadata.readonly']\n",
    "\n",
    "\n",
    "# # Path to your credentials file\n",
    "# creds_file_path = 'C:/Users/Arnell/Documents/GitHub/whisp_sustaain/whisp/src/credentials.json'\n",
    "\n",
    "\n",
    "# # Function to authenticate and create a service\n",
    "# def authenticate_and_build_service():\n",
    "#     creds = None\n",
    "#     # The file token.json stores the user's access and refresh tokens.\n",
    "#     if os.path.exists('token.json'):\n",
    "#         creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "#     # If there are no (valid) credentials available, let the user log in.\n",
    "#     if not creds or not creds.valid:\n",
    "#         if creds and creds.expired and creds.refresh_token:\n",
    "#             creds.refresh(Request())\n",
    "#         else:\n",
    "#             flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
    "#             creds = flow.run_local_server(port=0)\n",
    "#         # Save the credentials for the next run\n",
    "#         with open('token.json', 'w') as token:\n",
    "#             token.write(creds.to_json())\n",
    "\n",
    "#     # Build the Google Drive service\n",
    "#     service = build('drive', 'v3', credentials=creds)\n",
    "#     return service\n",
    "\n",
    "# # Function to list files in Google Drive\n",
    "# def list_drive_files(service):\n",
    "#     results = service.files().list(\n",
    "#         pageSize=10,\n",
    "#         fields=\"nextPageToken, files(id, name)\"\n",
    "#     ).execute()\n",
    "#     items = results.get('files', [])\n",
    "\n",
    "#     if not items:\n",
    "#         print('No files found.')\n",
    "#     else:\n",
    "#         print('Files:')\n",
    "#         for item in items:\n",
    "#             print(f\"{item['name']} ({item['id']})\")\n",
    "\n",
    "# # Authenticate and create the service\n",
    "# drive_service = authenticate_and_build_service()\n",
    "\n",
    "# # List files in Google Drive\n",
    "# list_drive_files(drive_service)\n",
    "\n",
    "# # Function to authenticate and create credentials\n",
    "# def authenticate_and_save_credentials(creds_file_path):\n",
    "#     # Check if the credentials file already exists\n",
    "#     if os.path.exists(creds_file_path):\n",
    "#         creds = service_account.Credentials.from_service_account_file(creds_file_path, scopes=SCOPES)\n",
    "#     else:\n",
    "#         flow = InstalledAppFlow.from_client_secrets_file(creds_file_path, SCOPES)\n",
    "#         creds = flow.run_local_server(port=0)\n",
    "#         # Save the credentials for the next run\n",
    "#         with open(creds_file_path, 'w') as token:\n",
    "#             token.write(creds.to_json())\n",
    "\n",
    "#     return creds\n",
    "\n",
    "# # Call the function\n",
    "# credentials = authenticate_and_save_credentials(creds_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf073aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # from pydrive2.auth import GoogleAuth\n",
    "# # from pydrive2.drive import GoogleDrive\n",
    "\n",
    "\n",
    "# def download_file_from_drive(filename, folder_name):\n",
    "#     # Authenticate and create PyDrive client\n",
    "#     # gauth = GoogleAuth()\n",
    "#     # gauth.LocalWebserverAuth()\n",
    "#     # drive = GoogleDrive(gauth)\n",
    "\n",
    "#     # Search for the file by name in the specified folder\n",
    "#     query = f\"title = '{filename}' and '{folder_name}' in parents\"\n",
    "#     file_list = drive.ListFile({'q': query}).GetList()\n",
    "\n",
    "#     if file_list:\n",
    "#         file = file_list[0]  # Get the first matching file\n",
    "#         print(f\"Found file: {file['title']} (ID: {file['id']})\")\n",
    "\n",
    "#         # Download the file\n",
    "#         file.GetContentFile(filename)  # Save the file locally\n",
    "#         print(f\"File '{filename}' downloaded successfully.\")\n",
    "#     else:\n",
    "#         print(f\"File '{filename}' not found in Google Drive.\")\n",
    "\n",
    "# download_file_from_drive(filename='whisp_output_table.csv', folder_name='Whisp_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d350f25-0dc4-4c1f-99ab-9dcde029ff97",
   "metadata": {},
   "source": [
    "#### Add Geo ids (optional)\n",
    "##### Step 1. Register polygons:  compiles geo_ids in a lookup csv\n",
    "- NB registration takes a long time if many polygons (a few seconds each one). AgStack will update this in future. \n",
    "- If processing doesn't complete, just rerun this cell and it should pickup from where you left.\n",
    "- If registering many features you can also click dollar sign in bottom right of Sepal and under 'Sessions' heading extend the length as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a8405b8-23a4-466e-b9be-0791c7b47935",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'register_fc_and_append_to_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mregister_fc_and_append_to_csv\u001b[49m(\n\u001b[0;32m      2\u001b[0m     feature_col\u001b[38;5;241m=\u001b[39mroi,\n\u001b[0;32m      3\u001b[0m     geo_id_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     output_lookup_csv\u001b[38;5;241m=\u001b[39mout_directory\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_geo_id_lookup.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     join_id_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem:index\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     override_checks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      7\u001b[0m     remove_temp_csv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      8\u001b[0m     debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'register_fc_and_append_to_csv' is not defined"
     ]
    }
   ],
   "source": [
    "register_fc_and_append_to_csv(\n",
    "    feature_col=roi,\n",
    "    geo_id_column=\"Geo_id\",\n",
    "    output_lookup_csv=out_directory/\"temp_geo_id_lookup.csv\",\n",
    "    join_id_column=\"system:index\",\n",
    "    override_checks=False,\n",
    "    remove_temp_csv=False,\n",
    "    debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f6c36d-3e62-4e95-9976-11e98215ee4e",
   "metadata": {},
   "source": [
    "##### Step 2. Join geo ids from lookup csv to Whisp stats csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5018ba-bf5d-41e3-9860-fb52c4c8c2d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "add_geo_ids_to_csv_from_lookup_csv(\n",
    "        input_csv=out_directory/\"whisp_output_table_w_risk.csv\",\n",
    "        geo_id_lookup_csv=out_directory/\"temp_geo_id_lookup.csv\",\n",
    "        join_id_column=\"system:index\",\n",
    "        geo_id_column=geo_id_column,\n",
    "        overwrite=False,\n",
    "        drop_geo=False,\n",
    "        debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3135797-0ac3-4b67-9584-f395436601bc",
   "metadata": {},
   "source": [
    "##### Optional: remove \"system:index\" column \n",
    "NB this is needed for joining geo_ids to csv (from lookup table). Check you have all your geo_ids first and if in doubt run on a copy of the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069233ff-db06-4d09-b423-4f7d83630013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_column_from_csv(\n",
    "#     csv_file=\"whisp_output_table_w_risk_w_geo_id.csv\", # this may change depending on if overwrite is on\n",
    "#     column_name=\"system:index\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
